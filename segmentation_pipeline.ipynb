{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fr_core_news_md\n",
    "\n",
    "nlp = fr_core_news_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_doc(text):\n",
    "    #V2 : regrouper les enfants isolés de la racine avec la racine\n",
    "\n",
    "    doc = nlp(text)                      #pour traiter un ensemble de documents, utiliser docs =nlp.pipe(DOCS)\n",
    "\n",
    "    \n",
    "    segments = []\n",
    "    roots = [token for token in doc if token.head == token]\n",
    "    for root in roots: \n",
    "        seg_root = []\n",
    "        for token in root.lefts:                  #segmenter en sous-arbre\n",
    "            if len(list(token.subtree)) == 1:\n",
    "                seg_root.append(token)\n",
    "            else: \n",
    "                temp = []\n",
    "                for descendant in token.subtree:            \n",
    "                    if descendant.text == \",\":        #segmenter en virgule\n",
    "                        temp.append(descendant)\n",
    "                        segments.append(temp)\n",
    "                        temp = []\n",
    "                    else:\n",
    "                        temp.append(descendant)\n",
    "                if len(temp) != 0:\n",
    "                    segments.append(temp)\n",
    "        position_root = len(segments)            \n",
    "        seg_root.append(root)\n",
    "        \n",
    "        for token in root.rights:\n",
    "            if len(list(token.subtree)) == 1:\n",
    "                seg_root.append(token)\n",
    "            else: \n",
    "                temp = []\n",
    "                for descendant in token.subtree:            \n",
    "                    if descendant.text == \",\":        \n",
    "                        temp.append(descendant)\n",
    "                        segments.append(temp)\n",
    "                        temp = []\n",
    "                    else:\n",
    "                        temp.append(descendant)\n",
    "                if len(temp) != 0:\n",
    "                    segments.append(temp)\n",
    "        segments.insert(position_root, seg_root)            \n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_doc(text):\n",
    "    #V2 : regrouper les enfants isolés de la racine avec la racine\n",
    "\n",
    "    doc = nlp(text)                      #pour traiter un ensemble de documents, utiliser docs =nlp.pipe(DOCS)\n",
    "\n",
    "    \n",
    "    segments = []\n",
    "    roots = [token for token in doc if token.head == token]\n",
    "    for root in roots: \n",
    "        seg_root = []\n",
    "        for token in root.lefts:                  #segmenter en sous-arbre\n",
    "            if (len(list(token.subtree)) == 1) & (token.pos_ not in ['SPACE','PUNCT']):\n",
    "                seg_root.append(token)\n",
    "            else: \n",
    "                temp = []\n",
    "                for descendant in token.subtree:            \n",
    "                    if (descendant.text == \",\") & (len(temp) != 0):        #segmenter en virgule\n",
    "                        segments.append(temp)\n",
    "                        temp = []\n",
    "                    else:\n",
    "                        if descendant.pos_ not in ['SPACE','PUNCT']:\n",
    "                            temp.append(descendant)\n",
    "                if len(temp) != 0:\n",
    "                    segments.append(temp)\n",
    "        position_root = len(segments)            \n",
    "        seg_root.append(root)\n",
    "        \n",
    "        for token in root.rights:\n",
    "            if (len(list(token.subtree)) == 1) & (token.pos_ not in ['SPACE','PUNCT']):\n",
    "                seg_root.append(token)\n",
    "            else: \n",
    "                temp = []\n",
    "                for descendant in token.subtree:            \n",
    "                    if (descendant.text == \",\") & (len(temp) != 0):        \n",
    "                        segments.append(temp)\n",
    "                        temp = []\n",
    "                    else:\n",
    "                        if descendant.pos_ not in ['SPACE','PUNCT']:\n",
    "                            temp.append(descendant)\n",
    "                if len(temp) != 0:\n",
    "                    segments.append(temp)\n",
    "        segments.insert(position_root, seg_root)            \n",
    "\n",
    "    return segments\n",
    "\n",
    "def has_verb(doc):\n",
    "    # déterminer si un segment contient un verbe\n",
    "    has_verb = False\n",
    "    for token in doc:\n",
    "        if token.pos_ in [\"VERB\", \"AUX\"]:\n",
    "            has_verb = True\n",
    "            break\n",
    "    return has_verb\n",
    "\n",
    "def seg2sent(seg):\n",
    "    # convertir un segment de token en un string de phrase\n",
    "    phrase = \"\"\n",
    "    for token in seg:\n",
    "        phrase += token.text + \" \" \n",
    "    return phrase\n",
    "\n",
    "def seg_doc_2(segments):\n",
    "    #version flatten\n",
    "    \n",
    "    temp = [seg for seg in segments]\n",
    "    for i,seg in enumerate(segments): \n",
    "        if has_verb(seg):                       # resegmenter les segments verbaux\n",
    "            new_segs = seg_doc(seg2sent(seg))\n",
    "            temp[i] = new_segs\n",
    "        else:\n",
    "            temp[i] = [segments[i]]\n",
    "    return [seg for segs in temp for seg in segs]\n",
    "\n",
    "def seg_auto(TEXT):\n",
    "    #resegmenter les segments verbaux tant que le nombre de segments augmente\n",
    "    segments = seg_doc(TEXT)\n",
    "    c = 0\n",
    "    while len(seg_doc_2(segments)) > len (segments):   \n",
    "        segments = seg_doc_2(segments)\n",
    "        c += 1\n",
    "        print(f\"segmenter {c} fois\")\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/rubing/Documents/Donnees/covax_content_sample_2000_medium_sized.csv\").drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Nous sommes dans une situation très préoccupante\". Lors d'une visioconférence organisée ce mercredi après-midi, le président du Conseil scientifique n'a pas caché son inquiétude face à l'évolution des indicateurs de l'épidémie de Covid-19 à l'échelle nationale. \"La reprise (de l'épidémie, NDLR) est plus importante en cette rentrée qu'on aurait pu l'imaginer\" , reconnait Jean-François Delfraissy.\n",
      "Même si ce rebond a encore \"peu de retentissement sur le nombre d'hospitalisation ou d'admissions en réa\", le risque, selon lui, serait d'être \"faussement rassuré par un certain nombre de chiffres\", alors même que \"la progression est exponentielle\" et que \"l' on sait qu'il va y avoir une accélération très rapide dans un deuxième temps\". \n",
      "\"L'image que l'on a de pouvoir faire une séparation entre les anciens et les plus jeunes (tranche d'âge majoritairement concernée par les nouvelles contaminations, NDLR) n'aura qu'un temps. Il y a forcément des liens qui vont se produire\".\n",
      "Jean-François Delfraissy (président du Conseil scientifique)\n",
      "L'inquiétude se concentre sur certaines régions, notamment PACA, où \"le système de soins pourrait se trouver en tension (...) dans les semaines qui viennent\", y compris en matière de lits de réanimation, poursuit-il, tout en rappelant l'importance du tryptique \"Tester - Tracer - Isoler\".  \"Il faut être autour du virus et limiter l'extension de l'épidémie\" .\n",
      "De nouvelles dispositions annoncées ce vendredi ?\n",
      "Dans ce contexte, \"le gouvernement va être obligé de prendre un certain nombre de décisions difficiles dans les 8 à 10 jours qui viennent, maximum\", prévient Jean-François Delfraissy.\n",
      "L'épidémie sera au centre d'un nouveau Conseil de défense , ce vendredi. L'exécutif devrait notamment se prononcer sur un éventuel raccourcissement de la durée de la période de quatorzaine pour les malades et les cas contact. Comme confirmé ce mercredi, le Conseil scientifique est \"favorable\" à un abaissement de cet  isolement de 14 à 7 jours.\n",
      "Stéphane Barnoin\n"
     ]
    }
   ],
   "source": [
    "TEXT=df.extracted_text[3]\n",
    "print(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmenter 1 fois\n",
      "segmenter 2 fois\n",
      "segmenter 3 fois\n",
      "segmenter 4 fois\n",
      "segmenter 5 fois\n",
      "segmenter 6 fois\n",
      "segmenter 7 fois\n"
     ]
    }
   ],
   "source": [
    "segs = seg_auto(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Nous, sommes],\n",
       " [dans, une, situation, très, préoccupante],\n",
       " [Lors, d],\n",
       " [une, visioconférence],\n",
       " [organisée],\n",
       " [ce, mercredi, après-midi],\n",
       " [le, président, du, Conseil, scientifique],\n",
       " [n, a, pas, caché],\n",
       " [son, inquiétude],\n",
       " [face, à, l', évolution, des, indicateurs, de, l', épidémie],\n",
       " [de, Covid-19, à, l', échelle, nationale],\n",
       " [La, reprise, de, l', épidémie],\n",
       " [NDLR],\n",
       " [est, plus, importante],\n",
       " [en, cette, rentrée],\n",
       " [qu, on, aurait, pu],\n",
       " [l, imaginer],\n",
       " [reconnait],\n",
       " [Jean-François, Delfraissy],\n",
       " [Même, si],\n",
       " [ce, rebond],\n",
       " [a, encore, peu],\n",
       " [de, retentissement],\n",
       " [sur, le, nombre, d, hospitalisation, ou, d, admissions, en, réa],\n",
       " [le],\n",
       " [risque],\n",
       " [selon, lui],\n",
       " [serait, d],\n",
       " [être, faussement, rassuré],\n",
       " [par, un, certain, nombre, de, chiffres],\n",
       " [alors, même],\n",
       " [la, progression],\n",
       " [que, est, exponentielle],\n",
       " [l, on],\n",
       " [et, que, sait],\n",
       " [qu, il, va],\n",
       " [y, avoir],\n",
       " [une, accélération, très, rapide],\n",
       " [dans, un, deuxième, temps],\n",
       " [L, image, que, l],\n",
       " [on, a],\n",
       " [de, pouvoir],\n",
       " [faire],\n",
       " [une, séparation],\n",
       " [entre, les, anciens],\n",
       " [plus, jeunes],\n",
       " [et, les, tranche],\n",
       " [d, âge],\n",
       " [majoritairement, concernée],\n",
       " [par, les, nouvelles, contaminations],\n",
       " [NDLR],\n",
       " [n, aura],\n",
       " [qu', un, temps],\n",
       " [Il, y, a, forcément],\n",
       " [des, liens],\n",
       " [qui, vont],\n",
       " [se, produire],\n",
       " [Jean-François, Delfraissy],\n",
       " [président, du, Conseil, scientifique],\n",
       " [L', inquiétude],\n",
       " [se, concentre],\n",
       " [sur, certaines, régions],\n",
       " [notamment, PACA],\n",
       " [le, système, de, soins],\n",
       " [où, pourrait],\n",
       " [se, trouver],\n",
       " [en, tension],\n",
       " [dans, les, semaines],\n",
       " [qui, viennent],\n",
       " [y, compris, en, matière, de, lits, de, réanimation],\n",
       " [poursuit, -il],\n",
       " [tout, en, rappelant],\n",
       " [l, importance, du, tryptique],\n",
       " [Tester],\n",
       " [Tracer],\n",
       " [-, Isoler],\n",
       " [Il, faut],\n",
       " [être, autour, du, virus],\n",
       " [et, limiter],\n",
       " [l, extension, de, l, épidémie],\n",
       " [De, nouvelles, dispositions],\n",
       " [annoncées],\n",
       " [ce, vendredi],\n",
       " [Dans, ce, contexte],\n",
       " [le, gouvernement],\n",
       " [va, maximum],\n",
       " [être, obligé],\n",
       " [de, prendre],\n",
       " [un, certain, nombre, de, décisions, difficiles],\n",
       " [8, à, 10],\n",
       " [dans, les, jours],\n",
       " [qui, viennent],\n",
       " [prévient],\n",
       " [Jean-François, Delfraissy],\n",
       " [L', épidémie],\n",
       " [sera, au, centre],\n",
       " [d', un, nouveau, Conseil, de, défense],\n",
       " [ce, vendredi],\n",
       " [L', exécutif],\n",
       " [devrait, notamment],\n",
       " [se, prononcer],\n",
       " [sur,\n",
       "  un,\n",
       "  éventuel,\n",
       "  raccourcissement,\n",
       "  de,\n",
       "  la,\n",
       "  durée,\n",
       "  de,\n",
       "  la,\n",
       "  période,\n",
       "  de,\n",
       "  quatorzaine,\n",
       "  pour,\n",
       "  les,\n",
       "  malades,\n",
       "  et,\n",
       "  les,\n",
       "  cas,\n",
       "  contact],\n",
       " [Comme, confirmé],\n",
       " [ce, mercredi],\n",
       " [le, Conseil, scientifique],\n",
       " [est, favorable],\n",
       " [à, un, abaissement, de, cet, isolement, de, 14, à, 7, jours],\n",
       " [Stéphane, Barnoin]]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
